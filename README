lang: python3
modules: regex, pkgutil, collections, unicodedata, time (Python lib)

References: 
1:	http://norvig.com/spell-correct.html
2:	https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings/For_machines
3:	http://ota.ahds.ac.uk/texts/0643.html

Terminology:
1:	ngram, language model, error model

Targets((X.Y) as major.minor):
1:		Basic norvig spell checker(english, devnagri..): using bigram model(edit distance 1 and 2).
2.1:	Model for learning(need to learn and get close to expected words with training).
2.2:	Edit set contains classes of same frequency words, utilise for correction.
3.0:	Getting corpus data and literals of language(unicode) from network directly, reducing static entries into source using crawlers.
3.1:	Choose method using flag=forMethod
3.2:	Log results with command line flag, -l for logging into results.txt (Logging in py3)
3.3:	Graph ploters(Insights for py3 graphs)

------- Not started
a:		form sentences from tags
b:		learning from scripts | docs examples.
c:		after creating ngram-model from particular doc, create sha1(doc + language used) and get data into particular processed form so next time for reprocessing arrives only when sha1 changes ie; new entry in doc changing it or language changes it.
-------

COMMENTS:
0:	Scripts (basic, enzyme, spelled, filecorct) are all independent examples.
	basic -- runs on small example set(<10) for testing if all works, ... fastly :) 
	filecorct â€”- linked with myBigErrorsList in corpus.eng and tries to correct it.
	spelled -- handles all testcases(small, medium, large, file...). Will add logging result. 
	tests -- basic(small set), test1(medium set(270)), test2(large set(400)), filetest() test case examples.
	enzyme -- to introduce learned() and get more comparisions of result using enzymetest().

	-------------------------------------
	-------------------------------------
	Corrections from python shell:
		Import package ngram(make sure in path)
		>>> 
		>>> from tools.ngram import NGram
		>>> 
		Set "language" option
		>>> language = "english"
		Create Language model for language
		>>> ng = NGram(language)
		>>> dword = "rint"
		>>> 
		>>> ng.correct(dword);
		'ring'
	-------------------------------------
	For basic, filecorct, spelled run with -h option too see more
	-------------------------------------

New Language: 
	For adding a new language get a book.txt inside corpus and make sure datapkg, lang, book params in tools.ngram.py is getting set in class NGram.__init__ and provide unicode(best suited) literals for new language inside tools.wordProcessor in class WordProcessor.charecterSet() which finally creates NGRAMS for the new language.
	Add small examples under testCases.basic.test(case) for your language case(before running test1 or test2) will be faster to remove any bugs if there :) . Currently this is messy will make it easier. 


Difference between spelltest() and learned():
1:	For cases where target is part of cndidates(correction set) ie; reachable,  but P(target) < P(correct(word)), hypothesis max(candidates) automatically chooses a word not expected adding a further bad case. In learned() we reduce the diff between target and chosen words after identifying such bad cases. Hence next runs the target has more chances of being choosen inside max(candidates).

2:	Similar points are provided from start with (bias > 0) runs(for all unknown words).

3:	learned() creates expectence-model as EXPEXTENCE def.dict after identifying expected word, hence learning in multiple runs(), as diff bw expected and choosen word can be large, without introducing unknowns into it and reducing particular bad cases. 


Runs Results:
1:	Unknowns are 0 after 1st run automatically(due to caching in or inserting explicitly) which reduces bad cases and increases correct answers on same set. Biasing also is doing the same as it inserts frequency of words by bias provided.  
2:	After 1st and 2nd runs the differences in result is randomly very small as unknowns already removed and the bad cases that remain are mostly unreachable words(not reachable within edit distance2) without changing NWORDS.



