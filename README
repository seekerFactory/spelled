lang: python3
modules: regex, collections, unicodedata, time

References: 
1:	http://norvig.com/spell-correct.html
2:	https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings/For_machines
3:	http://ota.ahds.ac.uk/texts/0643.html

Terminology:
1:	ngram
2:	Memoization
3:	language model, error model

Requirements:
1:	basic spell checker(english, devnagri..): using bigram model.
2:	add trigram model
3:	form sentences from tags
4:	learning from script examples to correct bash commands

COMMENTS:
0:	Scripts (basic, enzyme, test1, test2, filecorct) are all independent examples.
	Will get the (test* & basic) into one.
	basic -- runs on small example set(<10) for testing if all works fastly :) 
	test1 -- medium set(270) test cases.
	test2 -- large set(400) test cases.
	enzyme -- to compare learned() with spelltest(), which set needs to be mentioned.
	filecorct â€” linked with myBigErrorsList in corpus.eng and tries to correct it.

	[basic, test1, test2, filecorct] from python shell:
		>>> import basic
		>>> basic.main()
		similarly run for other any testcase runs 

	Corrections from python shell:
		>>> 
		>>> from tools.trainer import *
		>>> from tools.ngram import *
		>>> 
		>>> language = "english"
		>>> dword = "rint"
		>>>  _lang, NWORDS = setGlobalsWithLanguage(language);
		>>>  correct(dword);
		'ring'

	For adding any new lang just need to add a book inside corpus and make sure _inPath, _book, _lang parameters in tools.ngram.py is getting set under setGlobalsWithLanguage() and provide literals for lang inside tools.wordProcessor.charecterSet() which finally creates NGRAMS for the language.
	Best to add small example set under testCases.basic.test(), will be faster to check the rest when bugs removed.  

1:	Bigram model(edit_distance 2) at max yet.
2:	The main difference between spelltest() and learned() methods is that learned() reduces differcence between correct(word) and target which helps in next runs(only if target is part of cndidates ie; reachable,  but P(target) < P(correct(word)) ). This difference is provided automatically with (bias > 0) runs to some extent, hence result differences bw learned() and spelltest() are not very high in these cases. learned() is adding little bit of error-model into is as it compares P(target) and P(correct(word))

Runs with (bias=None) cases:
1:	Unknowns are 0 after 1st run
2:	After 1st, 2nd runs the difference in result is Null or random as the cases that remain can be only be improved further with edit_distance 3 algorithm included



